{
    "code": "import pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport os\nimport io\n\n# Create the directory if it doesn't exist\noutput_dir = \"uploads/8a6c356c-f3b2-41c8-a302-79cda3b22d2a\"\nos.makedirs(output_dir, exist_ok=True)\n\nurl = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n\n# Use pandas.read_html to read the table directly from the URL\n# The 'match' argument helps to select the correct table, looking for 'Worldwide gross' in headers\ntables = pd.read_html(url, match='Worldwide gross', flavor='bs4')\n\nif not tables:\n    raise ValueError(\"Could not find the table containing 'Worldwide gross' on the page.\")\n\ndf = tables[0]\n\n# Standardize column names by removing footnotes and extra spaces, and renaming for consistency\ndf.columns = df.columns.astype(str).str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\ndf = df.rename(columns={'Worldwide gross': 'Worldwide_gross'})\n\n# Data cleaning and type conversion\n# 'Rank': Remove footnotes/non-numeric chars, convert to numeric. Replace '\u2014' with NaN.\ndf['Rank'] = pd.to_numeric(df['Rank'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True).replace('\u2014', pd.NA), errors='coerce')\n\n# 'Worldwide_gross': Remove '$', ',', and footnotes, then convert to numeric (float).\ndf['Worldwide_gross'] = df['Worldwide_gross'].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False)\ndf['Worldwide_gross'] = pd.to_numeric(df['Worldwide_gross'].str.replace(r'\\[.*?\\]', '', regex=True), errors='coerce')\n\n# 'Year': Remove footnotes, convert to numeric (int).\ndf['Year'] = pd.to_numeric(df['Year'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True), errors='coerce')\n\n# 'Peak': Remove footnotes/non-numeric chars, convert to numeric. Replace '\u2014' with NaN.\ndf['Peak'] = pd.to_numeric(df['Peak'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True).replace('\u2014', pd.NA), errors='coerce')\n\n# Drop rows where critical columns (like Worldwide_gross, Year, Rank, Peak) are NaN after cleaning\ndf.dropna(subset=['Worldwide_gross', 'Year', 'Rank', 'Peak'], inplace=True)\n\n# Save the cleaned DataFrame to CSV\noutput_csv_path = os.path.join(output_dir, \"data.csv\")\ndf.to_csv(output_csv_path, index=False)\n\n# Generate metadata.txt\nmetadata_path = os.path.join(output_dir, \"metadata.txt\")\nwith open(metadata_path, 'w') as f:\n    f.write(\"Output of df.info():\\n\")\n    # Redirect df.info() output to a string buffer\n    buf = io.StringIO()\n    df.info(buf=buf)\n    f.write(buf.getvalue())\n    f.write(\"\\n\\nColumn names:\\n\")\n    f.write(str(df.columns.tolist()))\n    f.write(\"\\n\\nFirst few rows (df.head()):\\n\")\n    f.write(df.head().to_string())\n    f.write(\"\\n\\nANSWER_FORMAT:\\n\")\n    f.write(\"JSON array of strings\")",
    "libraries": [
        "pandas",
        "requests",
        "beautifulsoup4"
    ],
    "questions": [
        "How many $2 bn movies were released before 2000?",
        "Which is the earliest film that grossed over $1.5 bn?",
        "What's the correlation between the Rank and Peak?",
        "Draw a scatterplot of Rank and Peak along with a dotted red regression line through it. Return as a base-64 encoded data URI, \"data:image/png;base64,iVBORw0KG...\" under 100,000 bytes."
    ],
    "comment": "Step-3: Getting scrap code and metadata from llm. Tries count = %d 0"
}{
    "code": "import pandas as pd\nimport os\nimport re\nimport io\n\n# Define the output directory\noutput_dir = \"uploads/8a6c356c-f3b2-41c8-a302-79cda3b22d2a\"\nos.makedirs(output_dir, exist_ok=True)\n\n# URL of the Wikipedia page\nurl = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n\n# Read HTML tables into a list of DataFrames\n# The 'header=0' argument specifies that the first row of the table should be used as column headers.\n# 'html5lib' is a required dependency for pandas to parse HTML tables from web pages.\ntables = pd.read_html(url, header=0)\n\n# Identify the main table of highest-grossing films.\n# This table typically contains 'Worldwide gross' and 'Year' columns, which are essential for the questions.\ndf = None\n# Essential columns for identifying the correct table. These will be checked against normalized column names.\nexpected_cols_in_table = ['Worldwide gross', 'Year']\n\nfor table in tables:\n    # Normalize column names in the current table to make checking robust\n    # e.g., remove leading/trailing spaces, replace non-alphanumeric with spaces, then strip\n    normalized_cols = [re.sub(r'[^a-zA-Z0-9\\s]', '', col).strip() for col in table.columns.astype(str)]\n    \n    # Check if the normalized table contains all essential columns\n    if all(col in normalized_cols for col in expected_cols_in_table):\n        df = table\n        df.columns = normalized_cols # Apply normalized column names to the selected DataFrame\n        break\n\nif df is None:\n    raise ValueError(\"Could not find the expected table on the Wikipedia page with required columns.\")\n\n# Filter columns to only include those relevant for analysis and desired output.\n# Based on the questions, we need 'Rank', 'Peak', 'Title', 'Worldwide gross', and 'Year'.\n# We ensure they exist in the DataFrame before trying to select them.\nrelevant_columns = ['Rank', 'Peak', 'Title', 'Worldwide gross', 'Year']\ndf = df[[col for col in relevant_columns if col in df.columns]]\n\n# Clean and convert 'Worldwide gross' column\nif 'Worldwide gross' in df.columns:\n    df['Worldwide gross'] = df['Worldwide gross'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True) # Remove footnotes like [1] or [A]\n    df['Worldwide gross'] = df['Worldwide gross'].str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n    df['Worldwide gross'] = pd.to_numeric(df['Worldwide gross'], errors='coerce') # Convert to numeric, coercing errors to NaN\n\n# Clean and convert 'Year' column\nif 'Year' in df.columns:\n    df['Year'] = df['Year'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True) # Remove footnotes\n    df['Year'] = pd.to_numeric(df['Year'], errors='coerce') # Convert to numeric, coercing errors to NaN\n\n# Clean and convert 'Rank' and 'Peak' columns\nfor col in ['Rank', 'Peak']:\n    if col in df.columns:\n        df[col] = df[col].astype(str).str.replace(r'\\[.*?\\]', '', regex=True) # Remove footnotes\n        # Extract only the leading number. This handles cases like \"1[a]\" or \"1-2\" by taking '1'.\n        df[col] = df[col].apply(lambda x: re.search(r'^\\d+', str(x)).group(0) if re.search(r'^\\d+', str(x)) else None)\n        df[col] = pd.to_numeric(df[col], errors='coerce') # Convert to numeric, coercing errors to NaN\n\n# Drop rows where essential columns are NaN after cleaning (e.g., if gross or year couldn't be parsed).\n# This ensures that we have valid numeric data for subsequent analysis.\n# Only drop if the column exists after selection.\ndf.dropna(subset=[c for c in ['Worldwide gross', 'Year', 'Rank', 'Peak'] if c in df.columns], inplace=True)\n\n# Convert numeric columns to appropriate integer types where applicable, after dropping NaNs.\n# Using 'int' will convert float-like integers (e.g., 2009.0) to integers (2009).\nif 'Year' in df.columns:\n    df['Year'] = df['Year'].astype(int)\nif 'Rank' in df.columns:\n    df['Rank'] = df['Rank'].astype(int)\nif 'Peak' in df.columns:\n    df['Peak'] = df['Peak'].astype(int)\n\n# Save the processed DataFrame to CSV\noutput_csv_path = os.path.join(output_dir, \"data.csv\")\ndf.to_csv(output_csv_path, index=False)\n\n# Generate metadata.txt\nmetadata_path = os.path.join(output_dir, \"metadata.txt\")\nwith open(metadata_path, 'w') as f:\n    f.write(\"Output of df.info():\\n\")\n    # Capture df.info() output into a buffer and then write to file\n    buffer = io.StringIO()\n    df.info(buf=buffer)\n    f.write(buffer.getvalue())\n    f.write(\"\\nColumn names:\\n\")\n    f.write(\", \".join(df.columns) + \"\\n\")\n    f.write(\"\\nFirst few rows (df.head()):\\n\")\n    f.write(df.head().to_string() + \"\\n\")\n    f.write(\"\\nANSWER_FORMAT: JSON array of strings\\n\")\n",
    "libraries": [
        "pandas",
        "html5lib"
    ],
    "questions": [
        "How many $2 bn movies were released before 2000?",
        "Which is the earliest film that grossed over $1.5 bn?",
        "What's the correlation between the Rank and Peak?",
        "Draw a scatterplot of Rank and Peak along with a dotted red regression line through it. Return as a base-64 encoded data URI, \"data:image/png;base66,iVBORw0...\" under 100,000 bytes."
    ],
    "comment": "Step-4: Error occured while scrapping. Tries count = %d, 0"
}