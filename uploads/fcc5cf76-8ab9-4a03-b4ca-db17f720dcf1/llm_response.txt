{
    "code": "import pandas as pd\nimport requests\nimport os\nimport re\nimport io\n\n# Define paths\noutput_dir = 'uploads/fcc5cf76-8ab9-4a03-b4ca-db17f720dcf1'\ndata_path = os.path.join(output_dir, 'data.csv')\nmetadata_path = os.path.join(output_dir, 'metadata.txt')\n\n# Create directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# URL to scrape\nurl = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n\n# Scrape tables\nresponse = requests.get(url)\ntables = pd.read_html(response.text)\n\n# Identify the correct table: \"List of highest-grossing films\"\ndf = None\nfound_table = False\nfor table in tables:\n    # Normalize column names to lowercase and remove non-alphanumeric for matching\n    normalized_cols = {re.sub(r'[^a-z0-9]', '', col.lower()) for col in table.columns}\n    \n    # Check for essential columns based on content\n    if all(col_part in normalized_cols for col_part in ['rank', 'film', 'worldwidegross']):\n        if any(col_part.startswith('year') or col_part.startswith('release') for col_part in normalized_cols):\n            df = table\n            # Rename columns for consistency\n            col_mapping = {}\n            for current_col in table.columns:\n                normalized_current_col = re.sub(r'[^a-z0-9]', '', current_col.lower())\n                if normalized_current_col == 'rank':\n                    col_mapping[current_col] = 'Rank'\n                elif normalized_current_col == 'film':\n                    col_mapping[current_col] = 'Film'\n                elif normalized_current_col == 'worldwidegross':\n                    col_mapping[current_col] = 'Worldwide gross'\n                elif normalized_current_col.startswith('year') or normalized_current_col.startswith('release'):\n                    col_mapping[current_col] = 'Year'\n            \n            df = df.rename(columns=col_mapping)\n            # Ensure all target columns exist after renaming\n            if all(col in df.columns for col in ['Rank', 'Film', 'Worldwide gross', 'Year']):\n                found_table = True\n                break\n\nif not found_table:\n    raise ValueError(\"Could not find the 'List of highest-grossing films' table with expected columns.\")\n\n# Data Cleaning\n# Clean 'Worldwide gross' column\ndf['Worldwide gross'] = df['Worldwide gross'].astype(str)\ndf['Worldwide gross'] = df['Worldwide gross'].apply(lambda x: re.sub(r'\\[.*?\\]', '', x)) # Remove references like [1]\ndf['Worldwide gross'] = df['Worldwide gross'].apply(lambda x: re.sub(r'\\(.*?\\)', '', x)) # Remove content in parentheses\ndf['Worldwide gross'] = df['Worldwide gross'].apply(lambda x: re.sub(r'[$,]', '', x)) # Remove '$' and ','\ndf['Worldwide gross'] = pd.to_numeric(df['Worldwide gross'], errors='coerce') # Convert to numeric, coerce errors\n\n# Clean 'Year' column\ndf['Year'] = df['Year'].astype(str).str.extract(r'(\\d{4})')[0] # Extract the first 4-digit year\ndf['Year'] = pd.to_numeric(df['Year'], errors='coerce') # Convert to numeric\ndf.dropna(subset=['Year'], inplace=True) # Drop rows where Year became NaN\ndf['Year'] = df['Year'].astype(int)\n\n# Clean 'Rank' column\ndf['Rank'] = df['Rank'].astype(str).apply(lambda x: re.sub(r'\\[.*?\\]', '', x)) # Remove references\ndf['Rank'] = pd.to_numeric(df['Rank'], errors='coerce') # Coerce errors to NaN\ndf.dropna(subset=['Rank'], inplace=True) # Drop rows where Rank became NaN\ndf['Rank'] = df['Rank'].astype(int)\n\n# Select only the relevant columns\ndf = df[['Rank', 'Film', 'Worldwide gross', 'Year']]\n\n# Save the cleaned DataFrame to CSV\ndf.to_csv(data_path, index=False)\n\n# Generate metadata\nwith open(metadata_path, 'w') as f:\n    f.write(\"Output of df.info():\\n\")\n    info_buffer = io.StringIO()\n    df.info(buf=info_buffer)\n    f.write(info_buffer.getvalue())\n    \n    f.write(\"\\n\\nColumn names:\\n\")\n    f.write(str(df.columns.tolist()))\n    f.write(\"\\n\\nFirst few rows (df.head()):\\n\")\n    f.write(df.head().to_string())\n    f.write(\"\\n\\nANSWER_FORMAT: JSON array of strings containing the answer.\")\n",
    "libraries": [
        "pandas",
        "requests"
    ],
    "questions": [
        "How many $2 bn movies were released before 2000?",
        "Which is the earliest film that grossed over $1.5 bn?",
        "What's the correlation between the Rank and Peak?",
        "Draw a scatterplot of Rank and Peak along with a dotted red regression line through it."
    ],
    "comment": "Step-3: Getting scrap code and metadata from llm. Tries count = %d 2"
}{
    "code": "import pandas as pd\nimport requests\nimport os\nimport re\nimport io\n\n# --- Setup Paths ---\noutput_dir = \"uploads/fcc5cf76-8ab9-4a03-b4ca-db17f720dcf1\"\noutput_csv_path = os.path.join(output_dir, \"data.csv\")\nmetadata_path = os.path.join(output_dir, \"metadata.txt\")\n\n# Create output directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# --- Data Loading and Scraping ---\nurl = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n\n# Use pandas to read HTML tables directly\ntables = pd.read_html(url)\n\n# Find the correct table by checking for expected columns\ndf = None\nfor temp_df in tables:\n    # Normalize column names for comparison\n    temp_df.columns = temp_df.columns.astype(str).str.lower().str.replace(r'\\s+|[()\\[\\]]', '', regex=True)\n    if all(col in temp_df.columns for col in ['rank', 'worldwidegross', 'year']):\n        df = temp_df\n        break\n\nif df is None:\n    raise ValueError(\"Could not find the highest-grossing films table on the Wikipedia page.\")\n\n# --- Data Cleaning ---\n# Standardize column names again after selection to remove potential footnotes like [A]\ndf.columns = df.columns.astype(str).str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\ndf.columns = df.columns.str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.lower()\n\n# Ensure 'rank' and 'peak' are numeric\n# Handle potential non-numeric characters like 'No. 1' or '\u2014'\ndf['rank'] = pd.to_numeric(df['rank'].astype(str).str.replace(r'[^0-9]', '', regex=True), errors='coerce')\ndf['peak'] = pd.to_numeric(df['peak'].astype(str).str.replace(r'[^0-9]', '', regex=True), errors='coerce')\n\n# Clean 'worldwide_gross' column\n# Remove '$', ',', and any bracketed text like '[A]' or '[1]'\n# Convert to numeric (float)\ndef clean_gross(gross_str):\n    if pd.isna(gross_str):\n        return None\n    gross_str = str(gross_str)\n    gross_str = re.sub(r'\\$[A-Za-z]?\\s*', '', gross_str) # Remove '$' and optional currency code like '$US'\n    gross_str = gross_str.replace(',', '')\n    gross_str = re.sub(r'\\[.*?\\]', '', gross_str) # Remove footnotes\n    try:\n        return float(gross_str)\n    except ValueError:\n        return None\n\ndf['worldwide_gross'] = df['worldwide_gross'].apply(clean_gross)\n\n# Clean 'year' column\n# Some years might have ranges or text. Extract the first 4-digit number.\ndef clean_year(year_val):\n    if pd.isna(year_val):\n        return None\n    year_str = str(year_val)\n    match = re.search(r'\\b\\d{4}\\b', year_str)\n    if match:\n        return int(match.group(0))\n    return None\n\ndf['year'] = df['year'].apply(clean_year)\n\n# Drop rows where critical columns (like worldwide_gross or year) are NaN after cleaning\ndf.dropna(subset=['worldwide_gross', 'year', 'rank', 'peak'], inplace=True)\n\n# Convert relevant columns to their final types\ndf['rank'] = df['rank'].astype(int)\ndf['peak'] = df['peak'].astype(int)\ndf['year'] = df['year'].astype(int)\n\n# Sort by rank for consistency, as per Wikipedia table structure\ndf = df.sort_values(by='rank').reset_index(drop=True)\n\n# --- Save Data ---\ndf.to_csv(output_csv_path, index=False)\n\n# --- Generate Metadata ---\nmetadata_content = []\n\n# df.info() output\nmetadata_content.append(\"df.info():\\n\")\nbuffer = io.StringIO()\ndf.info(buf=buffer)\nmetadata_content.append(buffer.getvalue())\n\n# Column names\nmetadata_content.append(\"\\nColumn Names:\\n\")\nmetadata_content.append(\", \".join(df.columns.tolist()))\n\n# df.head() output\nmetadata_content.append(\"\\n\\nFirst Few Rows (df.head()):\\n\")\nmetadata_content.append(df.head().to_string())\n\n# ANSWER_FORMAT block\nmetadata_content.append(\"\\n\\nANSWER_FORMAT: JSON array of strings\")\n\nwith open(metadata_path, \"w\") as f:\n    f.write(\"\\n\".join(metadata_content))\n",
    "libraries": [
        "pandas",
        "requests",
        "lxml"
    ],
    "questions": [
        "How many $2 bn movies were released before 2000?",
        "Which is the earliest film that grossed over $1.5 bn?",
        "What's the correlation between the Rank and Peak?",
        "Draw a scatterplot of Rank and Peak along with a dotted red regression line through it. Return as a base-64 encoded data URI, \"data:image/png;base64,iVBORw0B...\" under 100,000 bytes."
    ],
    "comment": "Step-4: Error occured while scrapping. Tries count = %d, 0"
}{
    "code": "import pandas as pd\nimport requests\nimport os\nimport re\n\n# Define paths\noutput_dir = \"uploads/fcc5cf76-8ab9-4a03-b4ca-db17f720dcf1\"\ndata_path = os.path.join(output_dir, \"data.csv\")\nmetadata_path = os.path.join(output_dir, \"metadata.txt\")\n\n# Create the output directory if it does not exist\nos.makedirs(output_dir, exist_ok=True)\n\n# URL of the Wikipedia page\nurl = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n\n# Scrape the table\ntry:\n    # pd.read_html can directly parse tables from a URL\n    # Use match to find the specific table containing 'Worldwide gross'\n    tables = pd.read_html(url, match='Worldwide gross')\n    # Assuming the main table is the first one found that matches 'Worldwide gross'\n    df = tables[0].copy()\nexcept Exception as e:\n    raise RuntimeError(f\"Failed to scrape data from URL: {e}\")\n\n# Clean column names\n# Remove footnotes like [N] from column headers and strip whitespace\ndf.columns = [re.sub(r'\\\\[.*?\\]', '', col).strip() for col in df.columns]\n\n# Standardize column names for easier access (e.g., 'Worldwide gross' to 'Worldwide_Gross')\ndf.rename(columns={\n    'Worldwide gross': 'Worldwide_Gross'\n}, inplace=True)\n\n# Data Cleaning and Type Conversion\n# 1. 'Rank' column: Ensure it's numeric\ndf['Rank'] = pd.to_numeric(df['Rank'], errors='coerce')\n\n# 2. 'Worldwide_Gross' column: Remove '$', ',', and footnotes, then convert to numeric\n# Values might be like \"$2,923,706,026[1]\"\ndf['Worldwide_Gross'] = df['Worldwide_Gross'].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False)\ndf['Worldwide_Gross'] = df['Worldwide_Gross'].apply(lambda x: re.sub(r'\\\\[.*?\\]', '', x).strip())\ndf['Worldwide_Gross'] = pd.to_numeric(df['Worldwide_Gross'], errors='coerce')\n\n# 3. 'Year' column: Ensure it's numeric\ndf['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n\n# 4. 'Peak' column: Remove footnotes, convert to numeric\n# Values might be like \"1[2]\"\ndf['Peak'] = df['Peak'].astype(str).apply(lambda x: re.sub(r'\\\\[.*?\\]', '', x).strip())\ndf['Peak'] = pd.to_numeric(df['Peak'], errors='coerce')\n\n# 5. 'Film' column: Remove footnotes from film titles if any\ndf['Film'] = df['Film'].astype(str).apply(lambda x: re.sub(r'\\\\[.*?\\]', '', x).strip())\n\n# Drop rows where essential columns are NaN after conversion (e.g., Rank, Worldwide_Gross, Year, Peak)\ndf.dropna(subset=['Rank', 'Worldwide_Gross', 'Year', 'Peak'], inplace=True)\n\n# Convert Rank, Year, Peak to integer type after dropping NaNs\ndf['Rank'] = df['Rank'].astype(int)\ndf['Year'] = df['Year'].astype(int)\ndf['Peak'] = df['Peak'].astype(int)\n\n# Save the DataFrame to CSV\ndf.to_csv(data_path, index=False)\n\n# Generate metadata.txt\nwith open(metadata_path, 'w') as f:\n    f.write(\"Output of df.info():\\n\")\n    df.info(buf=f) # Write info to file buffer directly\n    f.write(\"\\n\\nColumn names:\\n\")\n    f.write(str(df.columns.tolist()))\n    f.write(\"\\n\\nFirst few rows (df.head()):\\n\")\n    f.write(df.head().to_string()) # Use to_string() for better formatting in text file\n    f.write(\"\\n\\nANSWER_FORMAT: JSON array of strings\")\n",
    "libraries": [
        "pandas",
        "requests"
    ],
    "questions": [
        "How many $2 bn movies were released before 2000?",
        "Which is the earliest film that grossed over $1.5 bn?",
        "What's the correlation between the Rank and Peak?"
    ],
    "comment": "Step-4: Error occured while scrapping. Tries count = %d, 1"
}{
    "code": "import pandas as pd\nimport requests\nfrom io import StringIO\nimport os\nimport re\n\n# Define output directory\noutput_dir = 'uploads/fcc5cf76-8ab9-4a03-b4ca-db17f720dcf1'\nos.makedirs(output_dir, exist_ok=True)\n\n# Define URL\nurl = 'https://en.wikipedia.org/wiki/List_of_highest-grossing_films'\n\n# Fetch HTML content\nresponse = requests.get(url)\nresponse.raise_for_status() # Raise an exception for HTTP errors\n\n# Use pandas to read HTML tables\ntables = pd.read_html(response.text)\n\ndf = None\n# Iterate through tables to find the one with 'Worldwide gross' and 'Year'\n# The main table is usually the first or second, and contains these key columns.\nfor table in tables:\n    # Check for presence of key columns, making sure to consider variations in column names like footnotes\n    if any('Worldwide gross' in col for col in table.columns) and any('Year' in col for col in table.columns) and any('Title' in col for col in table.columns):\n        df = table\n        break\n\nif df is None:\n    raise ValueError(\"Could not find the expected table on the Wikipedia page with 'Worldwide gross', 'Year', and 'Title' columns.\")\n\n# Clean column names by removing bracketed references (e.g., '[1]', '[a]')\ndf.columns = df.columns.astype(str).str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n\n# Standardize column names if they contain partial matches\n# Find the actual column names after cleaning for 'Worldwide gross', 'Rank', 'Peak', 'Year'\nworldwide_gross_col = next((col for col in df.columns if 'Worldwide gross' in col), None)\nyear_col = next((col for col in df.columns if 'Year' in col), None)\nrank_col = next((col for col in df.columns if 'Rank' in col), None)\npeak_col = next((col for col in df.columns if 'Peak' in col), None)\n\n# Data Cleaning and Type Conversion\nif worldwide_gross_col:\n    df.rename(columns={worldwide_gross_col: 'Worldwide gross'}, inplace=True)\n    df['Worldwide gross'] = df['Worldwide gross'].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n    df['Worldwide gross'] = df['Worldwide gross'].str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n    df['Worldwide gross'] = pd.to_numeric(df['Worldwide gross'], errors='coerce')\n\nif year_col:\n    df.rename(columns={year_col: 'Year'}, inplace=True)\n    df['Year'] = df['Year'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n    # Handle year ranges like '1999\u20132000' by taking the first year\n    df['Year'] = df['Year'].apply(lambda x: x.split('\u2013')[0].strip() if '\u2013' in x else x)\n    df['Year'] = pd.to_numeric(df['Year'], errors='coerce').astype('Int64') # Use Int64 for nullable integer\n\nif rank_col:\n    df.rename(columns={rank_col: 'Rank'}, inplace=True)\n    df['Rank'] = df['Rank'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n    df['Rank'] = pd.to_numeric(df['Rank'], errors='coerce').astype('Int64')\n\nif peak_col:\n    df.rename(columns={peak_col: 'Peak'}, inplace=True)\n    df['Peak'] = df['Peak'].astype(str).str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n    df['Peak'] = pd.to_numeric(df['Peak'], errors='coerce').astype('Int64')\n\n# Drop rows where essential numeric columns are NaN after cleaning\ndf.dropna(subset=['Worldwide gross', 'Year', 'Rank', 'Peak'], inplace=True)\n# Ensure Worldwide gross is positive\ndf = df[df['Worldwide gross'] > 0]\n\n# Save the cleaned DataFrame to data.csv\ndata_path = os.path.join(output_dir, 'data.csv')\ndf.to_csv(data_path, index=False)\n\n# Generate metadata.txt\nmetadata_path = os.path.join(output_dir, 'metadata.txt')\n\nwith open(metadata_path, 'w') as f:\n    f.write(\"Output of df.info():\\n\")\n    # Redirect df.info() to a string\n    buf = StringIO()\n    df.info(buf=buf)\n    f.write(buf.getvalue())\n    f.write(\"\\n\\nColumn names:\\n\")\n    f.write(str(df.columns.tolist()))\n    f.write(\"\\n\\nFirst few rows (df.head()):\\n\")\n    f.write(df.head().to_string())\n    f.write(\"\\n\\nANSWER_FORMAT: JSON\\n\")\n    f.write(f\"\\nSaved file: {data_path} - Highest-grossing films data\\n\")\n",
    "libraries": [
        "pandas",
        "requests",
        "beautifulsoup4"
    ],
    "questions": [
        "How many $2 bn movies were released before 2000?",
        "Which is the earliest film that grossed over $1.5 bn?",
        "What's the correlation between the Rank and Peak?",
        "Draw a scatterplot of Rank and Peak along with a dotted red regression line through it. Return as a base-64 encoded data URI, \"data:image/png;base64,iVBORw0...\" under 100,000 bytes."
    ],
    "comment": "Step-4: Error occured while scrapping. Tries count = %d, 2"
}